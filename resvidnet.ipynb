{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marcjuniornkengue/resvidnet?scriptVersionId=91692201\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"### Import Libraries and activate TPU\nImporting the libraries and activate TPU to accelerate data processing and model training.","metadata":{"id":"doPnNZ4RXpP0"}},{"cell_type":"code","source":"#### Import libraries\nimport os\n!pip install tensorflow_addons\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow import keras\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.metrics import classification_report\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nimport sklearn\nimport itertools\nfrom tensorflow_addons.optimizers import CyclicalLearningRate\nimport matplotlib as mpl\nmpl.style.use('seaborn')\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nimport logging\nfrom random import choice\nimport random \n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# Set random seed\nnp.random.seed(123)","metadata":{"id":"-uEi4L86-Ak2","outputId":"d8cfdb8d-7161-4c46-e304-547d13317fe2","execution":{"iopub.status.busy":"2022-03-28T06:42:18.244153Z","iopub.execute_input":"2022-03-28T06:42:18.245009Z","iopub.status.idle":"2022-03-28T06:42:31.838058Z","shell.execute_reply.started":"2022-03-28T06:42:18.244965Z","shell.execute_reply":"2022-03-28T06:42:31.837139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metrics functions plot\nPlotting Accuracy and loss curve, for train and validation data.\nThe training loss indicates how well the model is fitting the training data, while the validation loss indicates how well the model fits validation data.\nThe training accuracy indicates how accurate the model is for the training data, while the validation accuracy indicates how accurate the model is for validation data.","metadata":{"id":"LeaWUaULXpQB"}},{"cell_type":"code","source":"def metrics_plot(history, field, fn):\n    def plot(data, val_data, best_index, best_value, title):\n        plt.plot(range(1, len(data)+1), data, label='train')\n        plt.plot(range(1, len(data)+1), val_data, label='validation')\n        if not best_index is None:\n            plt.axvline(x=best_index+1, linestyle=':', c=\"#777777\")\n        if not best_value is None:\n            plt.axhline(y=best_value, linestyle=':', c=\"#777777\")\n        plt.xlabel('Epoch')\n        plt.ylabel(field)\n        plt.xticks(range(0, len(data), 20))\n        plt.title(title)\n        plt.legend()\n        plt.savefig('{} curve.jpg'.format(field), format='jpg', dpi=300)\n        plt.show()\n        \n        \n\n    data = history.history[field]\n    val_data = history.history['val_' + field]\n    tail = int(0.15 * len(data))\n\n    best_index = fn(val_data)\n    best_value = val_data[best_index]\n\n    plot(data, val_data, best_index, best_value, \"{} over epochs (best {:06.4f})\".format(field, best_value))\n    #plot(data[-tail:], val_data[-tail:], None, best_value, \"{} over last {} epochs\".format(field, tail))","metadata":{"id":"qVVuZKOcosqA","execution":{"iopub.status.busy":"2022-03-28T08:24:01.495502Z","iopub.execute_input":"2022-03-28T08:24:01.496205Z","iopub.status.idle":"2022-03-28T08:24:01.505932Z","shell.execute_reply.started":"2022-03-28T08:24:01.496166Z","shell.execute_reply":"2022-03-28T08:24:01.505191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix plot\nThe function print and plot the confusion matrix.\nIt's a specific table layout that allows visualization of the performance of the model. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class.","metadata":{"id":"JyJANVbQXpQE"}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.savefig('{}.jpg'.format(title), format='jpg', dpi=300)","metadata":{"id":"tx-GcyFx_TVR","execution":{"iopub.status.busy":"2022-03-28T06:42:31.851559Z","iopub.execute_input":"2022-03-28T06:42:31.851847Z","iopub.status.idle":"2022-03-28T06:42:31.865943Z","shell.execute_reply.started":"2022-03-28T06:42:31.851804Z","shell.execute_reply":"2022-03-28T06:42:31.86525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ECG Signal classes\nThe class of the signals.\n* Normal : Label for Normal ECG signal.\n* HB : Label for abnormal ECG signal.\n* PMI : Label for ECG signal of person with history of Myocardial Infarction.\n* MI : Label for ECG signal of person with Myocardial Infarction.\n* COVID : Label for ECG signal of person with COVID-19.","metadata":{"id":"G-KIxQmpXpQF"}},{"cell_type":"code","source":"classes=['Normal','HB','PMI', 'MI','COVID']","metadata":{"id":"PZ9CZMqgcvEP","execution":{"iopub.status.busy":"2022-03-28T06:42:31.868383Z","iopub.execute_input":"2022-03-28T06:42:31.868663Z","iopub.status.idle":"2022-03-28T06:42:31.884568Z","shell.execute_reply.started":"2022-03-28T06:42:31.868629Z","shell.execute_reply":"2022-03-28T06:42:31.883536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading dataset and plot class repartition\nLoading ECG dataset, and plotting data repartition per class.","metadata":{"id":"0kXvOLGIXpQH"}},{"cell_type":"code","source":"## Load data\ndf=pd.read_csv('../input/ecg-signal-covid/covid_dataset_balanced.csv',header=None)\ndf.reset_index(drop=True, inplace=True)\n\n## Get features and label\nx=df.iloc[:,:-1].values # Signal data\ny=df.iloc[:,-1].values  # Signal label\n\nprint(df) # Display dataset\n\n## Data repartition per class \nper_class = df.iloc[:,-1].value_counts() \nplt.figure(figsize=(20,10))\nmy_circle=plt.Circle( (0,0), 0.7, color='white')\nplt.pie(per_class, labels=['Normal','HB','PMI', 'MI','COVID'], colors=['tab:blue','tab:orange','tab:purple','tab:olive','tab:green'],autopct='%1.1f%%')\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","metadata":{"id":"2dxfYVHmCgjC","outputId":"0604f19d-407b-4bf4-e215-562ff553ba0a","execution":{"iopub.status.busy":"2022-03-28T06:42:31.885967Z","iopub.execute_input":"2022-03-28T06:42:31.88666Z","iopub.status.idle":"2022-03-28T06:43:17.821941Z","shell.execute_reply.started":"2022-03-28T06:42:31.886608Z","shell.execute_reply":"2022-03-28T06:43:17.820863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train,test and validation split\nThe dataset is split into three subsets : \n* The train dataset, for training the model\n* The validation dataset, to validate the model\n* The test dataset, to evaluate the model","metadata":{"id":"f_RfF1v0XpQI"}},{"cell_type":"code","source":"y=y.astype(int) # Convert label into int\n## Split into train and test\nX_train, X_val, y_train, y_val = train_test_split(x,y, test_size=0.2, random_state=np.random.randint(1,1000, 1)[0], shuffle = True)\n## Slip into test and validation\nX_val, X_test, y_val, y_test  = train_test_split(X_val, y_val, test_size=0.5, random_state=np.random.randint(1,1000, 1)[0], shuffle = True)\n\n## Expand data dimension for the Deep Learning Model\n## Train data\nX_train = np.expand_dims(X_train, -1)\ny_train = np.expand_dims(y_train, -1)\n## Validation data\nX_val = np.expand_dims(X_val, -1)\ny_val = np.expand_dims(y_val, -1)\n\n## Test data\nX_test = np.expand_dims(X_test, -1)\ny_test = np.expand_dims(y_test, -1)\n","metadata":{"id":"o6Ol06PK_Sfm","execution":{"iopub.status.busy":"2022-03-28T06:43:17.823268Z","iopub.execute_input":"2022-03-28T06:43:17.823516Z","iopub.status.idle":"2022-03-28T06:43:21.296724Z","shell.execute_reply.started":"2022-03-28T06:43:17.823488Z","shell.execute_reply":"2022-03-28T06:43:21.296044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=x[0]\nplt.plot(data)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:43:21.29778Z","iopub.execute_input":"2022-03-28T06:43:21.29861Z","iopub.status.idle":"2022-03-28T06:43:21.544675Z","shell.execute_reply.started":"2022-03-28T06:43:21.298564Z","shell.execute_reply":"2022-03-28T06:43:21.544048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### The ResvidNet Model\nThe model is inspired by ResNet18. Residual block of ResNet network is enhance by adding:\n* A Batch Normalization Layer, to normalize all datas for training\n* More Conv1D layers with higher filters numbers, to learning signal features better,faster and increase accuracy\n* Dropout Layers and regularization Layers , in order to prevent overfitting.\nThe input of the overall model is a Conv1D layer, follow by a Gaussian Noise Layer was also added, to make the model more robust.","metadata":{"id":"tePFg9_kXpQJ"}},{"cell_type":"code","source":"def dnn_model(im_shape):\n    inputs_cnn=keras.layers.Input(shape=(im_shape), name='inputs_cnn')\n    conv1_1=keras.layers.Dense(1024, activation='relu')(inputs_cnn)\n    conv1_1=keras.layers.Dropout(0.3)(conv1_1)\n    pool1=keras.layers.Dense(1024, activation='relu')(conv1_1)\n    conv2_1=keras.layers.Dropout(0.3)(pool1)\n    conv2_1=keras.layers.Dense(512, activation='relu')(conv2_1)\n    pool2=keras.layers.Dropout(0.2)(conv2_1)\n    conv3_1=keras.layers.Dense(128, activation='relu')(pool2)\n    dense_end2 = keras.layers.Dense(64, activation='relu')(conv3_1)\n    main_output = keras.layers.Dense(5, activation='softmax', name='main_output')(dense_end2)\n    model = keras.Model(inputs= inputs_cnn, outputs=main_output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:43:21.545616Z","iopub.execute_input":"2022-03-28T06:43:21.545951Z","iopub.status.idle":"2022-03-28T06:43:21.554566Z","shell.execute_reply.started":"2022-03-28T06:43:21.545921Z","shell.execute_reply":"2022-03-28T06:43:21.553599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cnn_model_ecg(im_shape):    \n    inputs_cnn=keras.layers.Input(shape=(im_shape), name='inputs_cnn')\n    conv1_1=keras.layers.Convolution1D(64, (5), activation='relu', input_shape=im_shape)(inputs_cnn)\n    conv1_1=keras.layers.BatchNormalization()(conv1_1)\n    pool1=keras.layers.MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv1_1)\n    conv2_1=keras.layers.Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)\n    conv2_1=keras.layers.BatchNormalization()(conv2_1)\n    pool2=keras.layers.MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n    conv3_1=keras.layers.Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)\n    conv3_1=keras.layers.BatchNormalization()(conv3_1)\n    pool3=keras.layers.MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n    flatten=keras.layers.Flatten()(pool3)\n    flatten= keras.layers.Dropout(0.3)(flatten)\n    dense_end1 = keras.layers.Dense(128, activation='relu')(flatten)\n    dense_end2 = keras.layers.Dense(32, activation='relu')(dense_end1)\n    main_output = keras.layers.Dense(5, activation='softmax', name='main_output')(dense_end2)\n    model = keras.Model(inputs= inputs_cnn, outputs=main_output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:43:21.556064Z","iopub.execute_input":"2022-03-28T06:43:21.558277Z","iopub.status.idle":"2022-03-28T06:43:21.569923Z","shell.execute_reply.started":"2022-03-28T06:43:21.558238Z","shell.execute_reply":"2022-03-28T06:43:21.568807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef resnet(im_shape):\n    ## The residual block of ResVidNet\n    def residual_block(X, kernels, stride):\n        out = keras.layers.Conv1D(kernels, stride,  kernel_regularizer=l2(0.001),padding='same')(X)\n        out = keras.layers.ReLU()(out)\n        \n        out = keras.layers.Conv1D(kernels, stride,  kernel_regularizer=l2(0.001),padding='same')(out)\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.Conv1D(kernels, stride, kernel_regularizer=l2(0.001) ,padding='same')(out)\n        \n        out = keras.layers.add([X, out])\n        out = keras.layers.ReLU()(out)\n        \n        out = keras.layers.MaxPool1D(5, 2)(out)\n        \n        return out\n    \n    kernels = 64\n    stride = 5\n\n\n    inputs = keras.layers.Input(im_shape)\n    X = keras.layers.Conv1D(kernels, stride)(inputs)\n    #X = keras.layers.GaussianNoise(0.01)(X)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = keras.layers.Flatten()(X)\n    X = keras.layers.Dense(32, activation='relu')(X)\n    X = keras.layers.Dense(32, activation='relu')(X)\n    output = keras.layers.Dense(5, activation='softmax')(X)\n\n    model = keras.Model(inputs=inputs, outputs=output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:43:21.572642Z","iopub.execute_input":"2022-03-28T06:43:21.573066Z","iopub.status.idle":"2022-03-28T06:43:21.591325Z","shell.execute_reply.started":"2022-03-28T06:43:21.573035Z","shell.execute_reply":"2022-03-28T06:43:21.590358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef ResVidNet(im_shape):\n    ## The residual block of ResVidNet\n    def residual_block(X, kernels, stride):\n        out = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(X)\n        \n        out = keras.layers.Conv1D(kernels, stride,  kernel_regularizer=l2(0.005),padding='same')(out)\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.Dropout(0.1)(out) \n        \n        out = keras.layers.Conv1D(kernels, stride,  kernel_regularizer=l2(0.005),padding='same')(out)\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.Dropout(0.1)(out) \n        \n        out = keras.layers.Conv1D(kernels, stride,  kernel_regularizer=l2(0.005),padding='same')(out)\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.Dropout(0.1)(out) \n        \n        out = keras.layers.Conv1D(kernels, stride,  kernel_regularizer=l2(0.005),padding='same')(out)\n        out = keras.layers.Dropout(0.1)(out) \n        out = keras.layers.ReLU()(out)\n        \n        out = keras.layers.Conv1D(kernels, stride, kernel_regularizer=l2(0.005) ,padding='same')(out)\n        \n        out = keras.layers.add([X, out])\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.MaxPool1D(5, 2)(out)\n        \n        return out\n    \n    kernels = 256\n    stride = 15\n\n\n    inputs = keras.layers.Input(im_shape,name='main_output')\n    X = keras.layers.Conv1D(kernels, stride)(inputs)\n    X = keras.layers.GaussianNoise(0.01)(X)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = keras.layers.Flatten()(X)\n    X = keras.layers.Dense(128, activation='relu')(X)\n    X = keras.layers.Dense(64, activation='relu')(X)\n    X = keras.layers.Dense(64, activation='relu')(X)\n    X = keras.layers.Dense(64, activation='relu')(X)\n    X = keras.layers.Dense(32, activation='relu')(X)\n    X = keras.layers.Dense(32, activation='relu')(X)\n    output = keras.layers.Dense(5, activation='softmax',name=\"last_conv\")(X)\n\n    model = keras.Model(inputs=inputs, outputs=output)\n    return model","metadata":{"id":"xCvWQ4hQXpQJ","execution":{"iopub.status.busy":"2022-03-28T08:39:37.5544Z","iopub.execute_input":"2022-03-28T08:39:37.554741Z","iopub.status.idle":"2022-03-28T08:39:37.574814Z","shell.execute_reply.started":"2022-03-28T08:39:37.554707Z","shell.execute_reply":"2022-03-28T08:39:37.574127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting the hyper-parameters, compiling and training the model","metadata":{"id":"4cs2sRMSXpQK"}},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:43:21.61598Z","iopub.execute_input":"2022-03-28T06:43:21.616814Z","iopub.status.idle":"2022-03-28T06:43:21.640472Z","shell.execute_reply.started":"2022-03-28T06:43:21.616737Z","shell.execute_reply":"2022-03-28T06:43:21.63964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Hyper parameters\nN=X_train.shape[0]\nbatch_size = 128 * tpu_strategy.num_replicas_in_sync\niterations = N/batch_size\nstep_size= 2 * iterations\nlr_schedule = CyclicalLearningRate(1e-5, 1e-3, step_size=step_size, scale_fn=lambda x: tf.pow(0.95,x))\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n    \nwith tpu_strategy.scope():\n        convidnet_model = ResVidNet((X_train.shape[1],1)) # Instanciate ResVidNet\n        resnet_model = resnet((X_train.shape[1],1)) # Instanciate ResVidNet\n        cnn_model = cnn_model_ecg((X_train.shape[1],1)) # Instanciate ResVidNet\n        d_model = dnn_model((X_train.shape[1],1)) # Instanciate ResVidNet\n        \n        early_stopping = EarlyStopping(monitor='val_loss', patience=80, verbose=1) # Early stopping parameters\n        save_best_weights_resvidnet = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True) # Model checkpoint parameters\n        save_best_weights_resnet = ModelCheckpoint(filepath=\"weights_resnet.hdf5\", verbose=1, save_best_only=True) # Model checkpoint parameters\n        save_best_weights_cnn = ModelCheckpoint(filepath=\"weights_cnn.hdf5\", verbose=1, save_best_only=True) # Model checkpoint parameters\n        save_best_weights_dnn = ModelCheckpoint(filepath=\"weights_dnn.hdf5\", verbose=1, save_best_only=True) # Model checkpoint parameters\n        \n        convidnet_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Model compiling\n        resnet_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Model compiling\n        cnn_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Model compiling\n        d_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Model compiling\n        \n        \n        #convidnet_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy']) # Model compiling\n\n## Model training\nhistory_resvidnet = convidnet_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=False,callbacks=[save_best_weights_resvidnet,early_stopping])\nhistory_resnet = resnet_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=False,callbacks=[save_best_weights_resnet,early_stopping])\nhistory_cnn = cnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=False,callbacks=[save_best_weights_cnn,early_stopping])\n#history_dnn = d_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=100, shuffle=False,callbacks=[save_best_weights_dnn,early_stopping])\n\n","metadata":{"id":"LDKRgBVoUVvo","outputId":"06fc7d06-7d77-4d32-9a5d-99124ec12703","execution":{"iopub.status.busy":"2022-03-28T08:39:50.931109Z","iopub.execute_input":"2022-03-28T08:39:50.931588Z","iopub.status.idle":"2022-03-28T09:24:53.95422Z","shell.execute_reply.started":"2022-03-28T08:39:50.931555Z","shell.execute_reply":"2022-03-28T09:24:53.953412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model evaluation\nThe model is evaluate using test data","metadata":{"id":"X4BLWlHsXpQK"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convidnet_model.load_weights('weights.hdf5') # Loading model\nX_covid_test = convidnet_model.evaluate(X_test, y_test) # Evaluate model\n\nresnet_model.load_weights('weights_resnet.hdf5') # Loading model\nX_resnet_test = resnet_model.evaluate(X_test, y_test) # Evaluate model\n\ncnn_model.load_weights('weights_cnn.hdf5') # Loading model\nX_cnn_test = cnn_model.evaluate(X_test, y_test) # Evaluate model\n\"\"\"\ndnn_model.load_weights('weights_dnn.hdf5') # Loading model\nX_dnn_test = dnn_model.evaluate(X_test, y_test) # Evaluate model\"\"\"","metadata":{"id":"Vx34H2CMO72O","execution":{"iopub.status.busy":"2022-03-28T09:27:39.499928Z","iopub.execute_input":"2022-03-28T09:27:39.500833Z","iopub.status.idle":"2022-03-28T09:27:57.795229Z","shell.execute_reply.started":"2022-03-28T09:27:39.50077Z","shell.execute_reply":"2022-03-28T09:27:57.794249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting Loss and Accuracy","metadata":{"id":"Qgb-CjCuXpQL"}},{"cell_type":"code","source":"metrics_plot(history_resvidnet, 'loss', lambda x: np.argmin(x))\nmetrics_plot(history_resvidnet, 'accuracy', lambda x: np.argmax(x))","metadata":{"id":"mFUS56l7ogVG","execution":{"iopub.status.busy":"2022-03-28T09:28:03.154104Z","iopub.execute_input":"2022-03-28T09:28:03.154804Z","iopub.status.idle":"2022-03-28T09:28:04.310599Z","shell.execute_reply.started":"2022-03-28T09:28:03.154762Z","shell.execute_reply":"2022-03-28T09:28:04.309722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting confusion matrix","metadata":{"id":"RHUlqF4AXpQM"}},{"cell_type":"code","source":"y_pred = tf.argmax(convidnet_model.predict(X_test), axis=-1)\n# Compute confusion matrix\ncnf_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Normal','HB','PMI', 'MI','COVID'],title=' Confusion matrix')\n\ny_pred1 = tf.argmax(resnet_model.predict(X_test), axis=-1)\n# Compute confusion matrix\ncnf_matrix1 = sklearn.metrics.confusion_matrix(y_test, y_pred1)\nnp.set_printoptions(precision=2)\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix1, classes=['Normal','HB','PMI', 'MI','COVID'],title=' Confusion matrix ResNet')\n\ny_pred2 = tf.argmax(cnn_model.predict(X_test), axis=-1)\n# Compute confusion matrix\ncnf_matrix2 = sklearn.metrics.confusion_matrix(y_test, y_pred2)\nnp.set_printoptions(precision=2)\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix2, classes=['Normal','HB','PMI', 'MI','COVID'],title=' Confusion matrix CNN')\n\"\"\"\ny_pred3 = tf.argmax(dnn_model.predict(X_test), axis=-1)\n# Compute confusion matrix\ncnf_matrix3 = sklearn.metrics.confusion_matrix(y_test, y_pred3)\nnp.set_printoptions(precision=2)\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix3, classes=['Normal','HB','PMI', 'MI','COVID'],title=' Confusion matrix')\"\"\"","metadata":{"id":"281teCwHO_Ox","execution":{"iopub.status.busy":"2022-03-28T09:28:17.269527Z","iopub.execute_input":"2022-03-28T09:28:17.27036Z","iopub.status.idle":"2022-03-28T09:28:26.148416Z","shell.execute_reply.started":"2022-03-28T09:28:17.270313Z","shell.execute_reply":"2022-03-28T09:28:26.147567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification report\nIt's a performance evaluation metric of the quality of predictions from ResVidNet. It's shows the precision, recall, F1 Score, and support.","metadata":{"id":"vsMcizwUXpQM"}},{"cell_type":"code","source":"df = pd.DataFrame(classification_report(y_pred, y_test, digits=2,output_dict=True)).T\ndf['support'] = df.support.apply(int)\ndf.rename(index={'0':'Normal', '1':'Abnormal HB', '2':'History of MI' ,'3':'Myocardial Infarction (MI)','4': 'COVID-19'}, inplace=True)\ndf = df[0:5]\ndf.style.background_gradient(cmap='viridis')\n","metadata":{"id":"wQVmSzXavhP4","execution":{"iopub.status.busy":"2022-03-28T09:39:11.922258Z","iopub.execute_input":"2022-03-28T09:39:11.922801Z","iopub.status.idle":"2022-03-28T09:39:11.977865Z","shell.execute_reply.started":"2022-03-28T09:39:11.922766Z","shell.execute_reply":"2022-03-28T09:39:11.976861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf1 = pd.DataFrame(classification_report(y_pred1, y_test, digits=2,output_dict=True)).T\ndf1['support'] = df1.support.apply(int)\ndf1.rename(index={'0':'Normal', '1':'Abnormal HB', '2':'History of MI' ,'3':'Myocardial Infarction (MI)','4': 'COVID-19'}, inplace=True)\ndf1 = df1[0:5]\ndf1.style.background_gradient(cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T09:28:39.546856Z","iopub.execute_input":"2022-03-28T09:28:39.547144Z","iopub.status.idle":"2022-03-28T09:28:39.597454Z","shell.execute_reply.started":"2022-03-28T09:28:39.547107Z","shell.execute_reply":"2022-03-28T09:28:39.596839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(classification_report(y_pred2, y_test, digits=2,output_dict=True)).T\ndf2['support'] = df2.support.apply(int)\ndf2.rename(index={'0':'Normal', '1':'Abnormal HB', '2':'History of MI' ,'3':'Myocardial Infarction (MI)','4': 'COVID-19'}, inplace=True)\ndf2 = df2[0:5]\ndf2.style.background_gradient(cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T09:28:51.326138Z","iopub.execute_input":"2022-03-28T09:28:51.326576Z","iopub.status.idle":"2022-03-28T09:28:51.379507Z","shell.execute_reply.started":"2022-03-28T09:28:51.326544Z","shell.execute_reply":"2022-03-28T09:28:51.378865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndf = pd.DataFrame(classification_report(y_pred3, y_test, digits=2,output_dict=True)).T\ndf['support'] = df.support.apply(int)\ndf.rename(index={'0':'Normal', '1':'Abnormal HB', '2':'History of MI' ,'3':'Myocardial Infarction (MI)','4': 'COVID-19'}, inplace=True)\ndf = df[0:5]\ndf.style.background_gradient(cmap='viridis')\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grad_cam(layer_name, data):\n    grad_model = tf.keras.models.Model(\n        [convidnet_model.inputs], [convidnet_model.get_layer(layer_name).output, convidnet_model.output]\n    )\n    last_conv_layer_output, preds = grad_model(data)\n    \n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(data)\n        pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n        \n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    \n    pooled_grads = tf.reduce_mean(grads,axis=(0))\n    \n    last_conv_layer_output = last_conv_layer_output[0]\n    \n    heatmap = last_conv_layer_output * pooled_grads\n    #heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    \n    heatmap = np.expand_dims(heatmap,0)\n    return heatmap","metadata":{"execution":{"iopub.status.busy":"2022-03-28T08:28:06.648051Z","iopub.execute_input":"2022-03-28T08:28:06.648881Z","iopub.status.idle":"2022-03-28T08:28:06.657012Z","shell.execute_reply.started":"2022-03-28T08:28:06.648838Z","shell.execute_reply":"2022-03-28T08:28:06.656005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_name = \"last_conv\"\nlabel = ['Normal','HB','PMI', 'MI','COVID']\ncnt = 0\nfor i in X_val[:100]:\n        pred = convidnet_model.predict(np.expand_dims(i,axis=0))\n        index=np.argmax(pred[0])\n        heatmap = grad_cam(layer_name,np.expand_dims(i,axis=0))\n        print(f\"Model prediction = {label[index]} ({pred[0][index]*100}), True label = {label[int(y_val[cnt])]}\")\n        plt.figure(figsize=(30,4))\n        plt.imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,1250,i.min(),i.max()], alpha=0.5)\n        plt.plot(i,'k')\n        plt.colorbar()\n        plt.show()\n        cnt +=1","metadata":{"execution":{"iopub.status.busy":"2022-03-28T08:28:09.665871Z","iopub.execute_input":"2022-03-28T08:28:09.666299Z","iopub.status.idle":"2022-03-28T08:31:01.102665Z","shell.execute_reply.started":"2022-03-28T08:28:09.666268Z","shell.execute_reply":"2022-03-28T08:31:01.101685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_name = \"last_conv\"\nlabel = ['Normal','HB','PMI', 'MI','COVID']\ncnt = 0\nT=[X_val[3],X_val[5],X_val[6],X_val[8],X_val[23]]\n\"\"\"\nfor i,j in zip(T,[4,7,14,38,49]):    \n        pred = convidnet_model.predict(np.expand_dims(i,axis=0))\n        index=np.argmax(pred[0])\n        heatmap = grad_cam(layer_name,np.expand_dims(i,axis=0))\n        plt.figure(figsize=(30,4))\n        plt.imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,375,i.min(),i.max()], alpha=0.5)\n        plt.title(f\"Model prediction = {label[index]} ({pred[0][index]*100})%,True label = {label[int(y_val[j])]}\")\n        plt.plot(i,'k')\n        plt.colorbar()\n        plt.show()\n        #plt.savefig('{}.eps'.format(cnt), format='eps', dpi=300)\n        cnt +=1\n\"\"\"\nfig, axs = plt.subplots(5, 1,figsize=(15,15))\npred = convidnet_model.predict(np.expand_dims(T[0],axis=0))\nindex=np.argmax(pred[0])\nheatmap = grad_cam(layer_name,np.expand_dims(T[0],axis=0))\npcm=axs[0].imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,1250,T[0].min(),T[0].max()], alpha=0.5)\naxs[0].set_title(f\"Model prediction = {label[index]} ({pred[0][index]*100})%, True label ={label[int(y_val[3])]}\")\naxs[0].plot(T[0],'k')\nfig.colorbar(pcm, ax=axs[0])\n\npred = convidnet_model.predict(np.expand_dims(T[1],axis=0))\nindex=np.argmax(pred[0])\nheatmap = grad_cam(layer_name,np.expand_dims(T[1],axis=0))\npcm=axs[1].imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,1250,T[1].min(),T[1].max()], alpha=0.5)\naxs[1].set_title(f\"Model prediction = {label[index]} ({pred[0][index]*100})%, True label = {label[int(y_val[5])]}\")\naxs[1].plot(T[1],'k')\nfig.colorbar(pcm, ax=axs[1])\n\npred = convidnet_model.predict(np.expand_dims(T[2],axis=0))\nindex=np.argmax(pred[0])\nheatmap = grad_cam(layer_name,np.expand_dims(T[2],axis=0)) \npcm=axs[2].imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,1250,T[2].min(),T[2].max()], alpha=0.5)\naxs[2].set_title(f\"Model prediction = {label[index]} ({pred[0][index]*100})%, True label = {label[int(y_val[6])]}\")\naxs[2].plot(T[2],'k')\nfig.colorbar(pcm, ax=axs[2])\n\npred = convidnet_model.predict(np.expand_dims(T[3],axis=0))\nindex=np.argmax(pred[0])\nheatmap = grad_cam(layer_name,np.expand_dims(T[3],axis=0))\npcm=axs[3].imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,1250,T[3].min(),T[3].max()], alpha=0.5)\naxs[3].set_title(f\"Model prediction = {label[index]} ({pred[0][index]*100})%, True label = {label[int(y_val[8])]}\")\naxs[3].plot(T[3],'k')\nfig.colorbar(pcm, ax=axs[3])\n\npred = convidnet_model.predict(np.expand_dims(T[4],axis=0))\nindex=np.argmax(pred[0])\nheatmap = grad_cam(layer_name,np.expand_dims(T[4],axis=0))\npcm=axs[4].imshow(np.expand_dims(heatmap,axis=2),cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,1250,T[4].min(),T[4].max()], alpha=0.5)\naxs[4].set_title(f\"Model prediction = {label[index]} ({pred[0][index]*100})%, True label = {label[int(y_val[23])]}\")\naxs[4].plot(T[4],'k')\nfig.colorbar(pcm, ax=axs[4])\n\nfig.tight_layout()\nplt.savefig('GRADCAM.jpg',format='jpg',dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T09:29:14.871014Z","iopub.execute_input":"2022-03-28T09:29:14.871297Z","iopub.status.idle":"2022-03-28T09:29:26.824643Z","shell.execute_reply.started":"2022-03-28T09:29:14.871268Z","shell.execute_reply":"2022-03-28T09:29:26.823802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data = history_resvidnet.history['val_accuracy']\nval_data1 = history_resnet.history['val_accuracy']\nval_data2 = history_cnn.history['val_accuracy']\n\nplt.plot(range(1, len(val_data)+1), val_data, label='ResvidNet')\nplt.plot(range(1, len(val_data1)+1), val_data1, label='ResNet')\nplt.plot(range(1, len(val_data2)+1), val_data2, label='CNN')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xticks(range(0, 100, 10))\nplt.title('Accuracy curves')\nplt.legend()\nplt.savefig('Accuracy curves.jpg', format='jpg', dpi=300)\nplt.show()\n    \nval_data = history_resvidnet.history['val_loss']\nval_data1 = history_resnet.history['val_loss']\nval_data2 = history_cnn.history['val_loss']\n\nplt.plot(range(1, len(val_data)+1), val_data, label='ResvidNet')\nplt.plot(range(1, len(val_data1)+1), val_data1, label='ResNet')\nplt.plot(range(1, len(val_data2)+1), val_data2, label='CNN')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.xticks(range(0, 100, 10))\nplt.title('Loss curves')\nplt.legend()\nplt.savefig('Loss curves.jpg', format='jpg', dpi=300)\nplt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T09:31:54.492828Z","iopub.execute_input":"2022-03-28T09:31:54.493177Z","iopub.status.idle":"2022-03-28T09:31:55.730961Z","shell.execute_reply.started":"2022-03-28T09:31:54.49312Z","shell.execute_reply":"2022-03-28T09:31:55.729954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimage = Image.open('./GRADCAM.jpg')\nim= image.convert('CMYK')\nim.save('GRADCAM.jpeg')\n\nimage = Image.open('./loss curve.jpg')\nim= image.convert('CMYK')\nim.save('loss curve.jpeg')\n\nimage = Image.open('./accuracy curve.jpg')\nim= image.convert('CMYK')\nim.save('accuracy curve.jpeg')\n\nimage = Image.open('./Loss curves.jpg')\nim= image.convert('CMYK')\nim.save('loss curves.jpeg')\n\nimage = Image.open('./Accuracy curves.jpg')\nim= image.convert('CMYK')\nim.save('accuracy curves.jpeg')\n\nimage = Image.open('./ Confusion matrix.jpg')\nim= image.convert('CMYK')\nim.save('Confusion matrix.jpeg')\n\nimage = Image.open('./ Confusion matrix ResNet.jpg')\nim= image.convert('CMYK')\nim.save('Confusion matrix ResNet.jpeg')\n\nimage = Image.open('./ Confusion matrix CNN.jpg')\nim= image.convert('CMYK')\nim.save('Confusion matrix CNN.jpeg')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T09:35:06.730596Z","iopub.execute_input":"2022-03-28T09:35:06.730979Z","iopub.status.idle":"2022-03-28T09:35:09.919407Z","shell.execute_reply.started":"2022-03-28T09:35:06.730943Z","shell.execute_reply":"2022-03-28T09:35:09.918373Z"},"trusted":true},"execution_count":null,"outputs":[]}]}